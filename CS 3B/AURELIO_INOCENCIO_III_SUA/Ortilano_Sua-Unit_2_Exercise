import neural_network_helper as nn



# a) Given the following inputs from the Iris Dataset, using the sepal length, sepal width, petal length and petal width, determine what class 
# (Iris-setosa, Iris-versicolor, and Iris-virginica) the following inputs are by calculating the output, given the neural network configurations:

#declaring the weights, inputs, and biases. 
target_output = [0.7,0.2,0.1]
inputs = [5.1, 3.5, 1.4, 0.2]

layer_1_weights = [[0.2, 0.1, -0.4, 0.6], [0.5, -0.2, 0.3, -0.1],[-0.3, 0.4, 0.2, 0.5]]
layer_1_bias = [3.0, -2.1, 0.6]

layer_2_weights = [[0.3,0.7,-0.6],[-0.5,0.2,0.4]]
layer_2_bias = [4.3, 6.4]

layer_3_weights = [[0.5,-0.2],[-0.3, 0.6],[0.8,-0.4]]
layer_3_bias = [-1.5, 2.1, -3.3]


#converting inputs and layer 1 weights with np.array to be able to persform dot operations
inputs, layer_1_weights = nn.setup_layer(inputs, layer_1_weights)

# weighted sum + bias
layer_1_output = nn.weighted_sum(inputs, layer_1_weights, layer_1_bias)

#performing Relu on the each layer 1 Output
for i in range(len(layer_1_output)):
        layer_1_output[i] = nn.activation_function(layer_1_output[i], activation_type="relu")

print("Output 2 (layer 1 with ReLU):", layer_1_output)



#converting layer 1 output and layer 2 weights with np.array to be able to persform dot operations
layer_1_output, layer_2_weights = nn.setup_layer(layer_1_output, layer_2_weights)

# weighted sum + bias
layer_2_output = nn.weighted_sum(layer_1_output, layer_2_weights, layer_2_bias)

#performing Relu on the each layer 2 Output
for i in range(len(layer_2_output)):
        layer_2_output[i] = nn.activation_function(layer_2_output[i], activation_type="sigmoid")

print("Output 2 (layer 2):", layer_2_output)



#converting layer 1 output and layer 2 weights with np.array to be able to persform dot operations
layer_2_output, layer_3_weights = nn.setup_layer(layer_2_output, layer_3_weights)

# weighted sum + bias
layer_3_output = nn.weighted_sum(layer_2_output, layer_3_weights, layer_3_bias)

#performing Softmax on layer 3 Outputs
layer_3_output= nn.activation_function(layer_3_output, activation_type="softmax")
loss = nn.calculate_loss(target_output, layer_3_output, "cross_entropy")

print("Output 3 (layer 3):", layer_3_output)
print("Loss: ", loss)
print("The class is Iris-versicolor since it has the highest value of ", max(layer_3_output), "from the output layer.") 



# Problem B: Breast Cancer Dataset
# Target: 1 = Malignant
target_output = [1]
inputs = [14.1, 20.3, 0.095]

# First Hidden Layer (ReLU)
layer_1_weights = [
    [0.5, -0.3, 0.8],
    [0.2,  0.4, -0.6],
    [-0.7, 0.9, 0.1]
]
layer_1_bias = [0.3, -0.5, 0.6]

# Second Hidden Layer (Sigmoid)
layer_2_weights = [
    [0.6, -0.2, 0.4],
    [-0.3, 0.5, 0.7]
]
layer_2_bias = [0.1, -0.8]

# Output Layer (Sigmoid)
layer_3_weights = [
    [0.7, -0.5]
]
layer_3_bias = [0.2]



# Setup and compute weighted sum for Layer 1
inputs, layer_1_weights = nn.setup_layer(inputs, layer_1_weights)
layer_1_output = nn.weighted_sum(inputs, layer_1_weights, layer_1_bias)

# Apply ReLU activation element-wise
for i in range(len(layer_1_output)):
    layer_1_output[i] = nn.activation_function(layer_1_output[i], activation_type="relu")

print("Output (Layer 1 with ReLU):", layer_1_output)



# Setup and compute weighted sum for Layer 2
layer_1_output, layer_2_weights = nn.setup_layer(layer_1_output, layer_2_weights)
layer_2_output = nn.weighted_sum(layer_1_output, layer_2_weights, layer_2_bias)

# Apply Sigmoid activation element-wise
for i in range(len(layer_2_output)):
    layer_2_output[i] = nn.activation_function(layer_2_output[i], activation_type="sigmoid")

print("Hidden Layer 2 (Output):", layer_2_output)



# Setup and compute weighted sum for Output Layer
layer_2_output, layer_3_weights = nn.setup_layer(layer_2_output, layer_3_weights)
layer_3_output = nn.weighted_sum(layer_2_output, layer_3_weights, layer_3_bias)

# Apply Sigmoid activation
final_output = nn.activation_function(layer_3_output, activation_type="sigmoid")

print("Final Output (Sigmoid):", final_output)



# Calculate losses
loss_cross_entropy = nn.calculate_loss(final_output, target_output, loss_type="cross_entropy")


print("Loss (Cross-Entropy):", loss_cross_entropy)


# Optional: Predicted class
predicted_class = 1 if float(final_output) >= 0.5 else 0
print("Predicted Class (0=Benign, 1=Malignant):", predicted_class)
